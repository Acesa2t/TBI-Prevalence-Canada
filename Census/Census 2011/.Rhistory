#'      -  AGEP - Age of population group
#'      -  YARP - Year of arrival of population group
#'      -  ISO3 - 3 letter country code corresponding to birth country
#'
#' OUTPUTS:
#' - A master table of all TB infection probabilities and outcomes,
#' stored in the outputs path specified below (path.out).
#'      -  NUMP - Number of persons in the population group
#'      -  AGEP - Age of population group
#'      -  YARP - Year of arrival of population group
#'      -  YOBP - Year of birth of population group
#'      -  BPLP - Birth country of population group
#'      -  ISO3 - 3 letter country code corresponding to birth country
#'      -  CNSY - Census year
#'      -  LTBP - Number of in the population estimated to have been infected
#'      -  PROB - Probability/risk of infection in the population group
#'
#' Author: Katie Dale and Milinda Abayawardana
#' Date created: 2016-2021
#'===================================================================================================================#
rm(list = ls(all.names = TRUE)) # Clears all objects includes hidden objects.
gc() # Frees up memory and report the memory usage.
#' LOAD REQUIRED LIBRARIES ==========================================================================================#
library(data.table)
library(tidyverse)
library(reshape2)
library(countrycode)
#' DEFINE USEFUL OBJECTS (INPUT & OUTPUT PATHS, FUNCTIONS, STUDY PERIOD ETC) ========================================#
#' The iso3 value for the country from which the census data is from
census.iso3 <- "CAN"
census.year <- 2016
#' This script will calculate the median hazard for each population
#' group in the census and, additionally, will provide lower and
#' upper percentile estimates, as defined by the following
#' objects.
low.percentile <- 0.25
high.percentile <- 0.75
#' Data inputs file path
path.in <- "/Users/ajordan/OneDrive - McGill University/LTBI-Aust-CEA-master/Data/"
#' Output file path
path.out <- "/Users/ajordan/OneDrive - McGill University/LTBI-Aust-CEA-master/Data/"
#' Source all functions, which are located within the "Functions" file.
source(paste0(path.in, "Functions.R"), encoding="utf-8")
#' INPUTS ===========================================================================================================#
#' Load the hazard data from Houben & Dodd
filename <- paste0(path.in, "5000repLARI.Rdata")
#tbhaz.5000rep <- load(filename)
#tbhaz.5000rep <- LARI
#tbhaz.5000rep
#rm(LARI)
filename <- paste0(path.in, "200repLARI.Rdata")
load(filename)
tbhaz.200rep <- as.data.table(rundata)
rm(rundata)
#' Load the census data
census <- read.csv(paste0(path.in, "census_classified.csv"),  header = T)
census <- census%>%filter(!ISO3 %in% c("FLK", "GIB", "GLP" ,"GUF" ,"LIE", "MTQ"))%>%select(-BPLP, -WHO_R)
# census <- read.csv(paste0(path.in, "Australia 2006.csv"), skip = 9, header = T)
# census <- read.csv(paste0(path.in, "Australia 2011.csv"), skip = 9, header = T)
#' Load TB data
tb <- read.csv(paste0(path.in, "NNDSS skeleton.csv"), header = T)
#' DATA PREP ========================================================================================================#
#' Creating cumulative FOIs and adjusting for census year.
#' Also expanding the table's year range ( 1889 to 2016).
tbhaz.200rep <- tbhazprep.function(tbhaz.200rep)
#tbhaz.5000rep <- tbhazprep.function(tbhaz.5000rep)
#' Clean the census data so that it has the following columns
#' AGEP, YARP, cob, NUMP, CNSY, YOBP and ISO3
#census <- CleanseCensus(census)
View(census)
#' Clean the TB data so that it has the following columns
#' AGEP, YARP, cob, NUMP, year, YOBP and ISO3
tb <- CleanseTBdata(tb)
tb <- subset(tb, year == census.year)
tb <- as.data.table(tb)
tb[, CNSY := as.numeric(year)]
#' Checking if there are any countries that don't have an
#' ISO3 match from Houben and Dodd.
setdiff(census$ISO3, tbhaz.200rep$iso3)
setdiff(tb$ISO3, census$ISO3)
setdiff(tb$ISO3, tbhaz.200rep$iso3)
setdiff(tbhaz.200rep$iso3, census$ISO3) #' All countries in the census data are captured in Houben & Dodd data.
#' Create a master look-up table of all probabilities of infection
#' for each population group, by using the census and tb tables
#' to get a list of unique ISO codes.
master.Prob <- CreateProbTables()
#' Subset the look-up table by ISO3 depending on whether the relevant tbhaz values
#' are in the tbhaz.200 or tbhaz.5000 data set.
# Our additions: Pakistan,Haiti, Somalia, Afghanistan, and Ethiopia, Sri Lanka-remove GBR and MYS
# Can ask Pete why they only did 6
prob.Inf200 <- master.Prob[ !(ISO3 %in% c(census.iso3))]
#' Also create a separate look-up table for the locally born.
prob.Inf.local <- master.Prob[ISO3 == census.iso3]
#' Tidy
rm(master.Prob)
#' The following function calculates hazards for the locally
#' born population (prob.Inf.local). The percentiles
#' that are required can be defined earlier in the script.
prob.Inf.local <- TBhazard.calc.function.local.born(prob.Inf.local, tbhaz.200rep)
#' Saving and removing file (memory management)
saveRDS(prob.Inf.local, file = paste0(path.out, "prob.Inf.local.rds"))
rm(prob.Inf.local)
#' The following function calculates hazards for the population
#' groups in the prob.Inf200 look-up table. The percentiles
#' that are required can be defined earlier in the script.
#' Because the hazard calculations are quite memory intensive,
#' I've split the data into groups by year of birth, before
#' running the function on it, so the chunks are more manageable.
#' Then the separate chunks are subsequently bound together again.
prob.Inf200[YOBP < 1987 , YOBPgroup := 1]
prob.Inf200[YOBP > 1986 & YOBP < 1993 , YOBPgroup := 2]
prob.Inf200[YOBP > 1992 & YOBP < 1999 , YOBPgroup := 3]
prob.Inf200[YOBP > 1998 & YOBP < 2005 , YOBPgroup := 4]
prob.Inf200[YOBP > 2004 & YOBP < 2011 , YOBPgroup := 5]
prob.Inf200[YOBP > 2010 , YOBPgroup := 6]
yob.split <- split(prob.Inf200, prob.Inf200$YOBPgroup)
yob.split <- lapply(yob.split, TBhazard.calc.function.overseas.born, tbhaz.200rep)
names(tbhaz.200rep)[names(tbhaz.200rep) == 'iso3'] <- 'ISO3'
dataf <- anti_join(yob.split[[1]], tbhaz.200rep, by = "ISO3")
unique(dataf$ISO3)
prob.Inf200 <- do.call("rbind", yob.split)
#' Tidy
rm(yob.split)
#' Saving and removing file (memory management)
saveRDS(prob.Inf200, file = paste0(path.out, "prob.Inf200.rds"))
#' Tidy
rm(prob.Inf200)
#' Repeat the same as above for the 5000rep look-up table.
#' However, with this table it is simplest to split it by ISO3,
#' rather than year of birth (because there are only six ISO3).
iso3.split <- split(prob.Inf5000, prob.Inf5000$ISO3)
iso3.split <- lapply(iso3.split, TBhazard.calc.function.overseas.born, tbhaz.200rep)
prob.Inf5000 <- do.call("rbind", iso3.split)
#' Saving and removing file (memory management)
saveRDS(prob.Inf5000, file = paste0(path.out, "prob.Inf5000.rds"))
rm(prob.Inf5000, iso3.split)
#' Order the census data.table.
census <- setorder(census, ISO3, YOBP, YARP)
#' Load the look-up tables back in.
prob.Inf200 <- readRDS(paste0(path.out, "prob.Inf200.rds"))
prob.Inf5000 <- readRDS(paste0(path.out, "prob.Inf5000.rds"))
prob.Inf.local <- readRDS(paste0(path.out, "prob.Inf.local.rds"))
#' Bind the look-up tables altogether to make the master look-up.
prob.Inf <- rbind(prob.Inf.local, prob.Inf200, prob.Inf5000, fill = T)
#' Tidy
prob.Inf <- rbind(prob.Inf.local, prob.Inf200, fill = T)
#' Calculating the probability of infection (PROB)
#' from the hazards.
prob.Inf[, PROB.med := 1 - exp(-(H.med))]
prob.Inf[, PROB.low := 1 - exp(-(H.low))]
prob.Inf[, PROB.high := 1 - exp(-(H.high))]
#' Calculating the number of in the population estimated
#' to have been infected (LTBP).
census[prob.Inf, LTBP := NUMP * PROB.med, on = .(ISO3, YOBP, YARP)]
census[prob.Inf, LTBP.low := NUMP * PROB.low, on = .(ISO3, YOBP, YARP)]
census[prob.Inf, LTBP.high := NUMP * PROB.high, on = .(ISO3, YOBP, YARP)]
#' Check the number missing LTBP information
census[is.na(LTBP), sum(NUMP)]
#' Check the percentage missing LTBP information
#' (some investigation may need to be done to work out
#' why these population groups have missing data. It
#' could be because some countries of birth were not
#' mapped to an ISO3 value).
census[is.na(LTBP), sum(NUMP)]/census[, sum(NUMP)] * 100
#' Merge in the TB data
census <- merge(census, tb, by = c("AGEP", "ISO3", "CNSY", "YARP"), all.x = T)
#' DATA OUTPUTS =======================================================================================================#
#' Save all the objects that haven't yet been saved.
saveRDS(prob.Inf, file = paste0(path.out, "prob.Inf.rds"))
saveRDS(census, file = paste0(path.out, "census.rds"))
#' HUGE NOTE: 1980 = ALL YEARS BEFORE 1981
cea_plane <- data.frame(intervention = c("Standard", "E","D","C","B","A"), cost = c(5000, 12000, 10000, 25000, 35000, 55000), effectiveness = c(1, 1.5, 2, 3, 4, 5))
cea_plane
ggplot(cea_plane, aes(effectiveness, cost, color = intervention)) +
geom_point(size = 4, alpha = 0.30)+
geom_text(label = c("Standard", "E","D","C","B","A"))+
labs(title = "Cost-Effectiveness Plane",
x = "Effectiveness (QALYs)",
y = "Cost ($)",
color = "Strategy")
library(tidyverse)
cea_plane <- data.frame(intervention = c("Standard", "E","D","C","B","A"), cost = c(5000, 12000, 10000, 25000, 35000, 55000), effectiveness = c(1, 1.5, 2, 3, 4, 5))
cea_plane
ggplot(cea_plane, aes(effectiveness, cost, color = intervention)) +
geom_point(size = 4, alpha = 0.30)+
geom_text(label = c("Standard", "E","D","C","B","A"))+
labs(title = "Cost-Effectiveness Plane",
x = "Effectiveness (QALYs)",
y = "Cost ($)",
color = "Strategy")
library(tidyverse)
cea_plane <- data.frame(intervention = c("Standard", "E","D","C","B","A"), cost = c(5000, 12000, 10000, 25000, 35000, 55000), effectiveness = c(1, 1.5, 2, 3, 4, 5))
cea_plane
ggplot(cea_plane, aes(effectiveness, cost, color = intervention)) +
geom_point(size = 6, alpha = 0.30)+
geom_text(label = c("Standard", "E","D","C","B","A"))+
labs(title = "Cost-Effectiveness Plane",
x = "Effectiveness (QALYs)",
y = "Cost ($)",
color = "Strategy")
library(tidyverse)
cea_plane <- data.frame(intervention = c("Standard", "E","D","C","B","A"), cost = c(5000, 12000, 10000, 25000, 35000, 55000), effectiveness = c(1, 1.5, 2, 3, 4, 5))
cea_plane
ggplot(cea_plane, aes(effectiveness, cost, color = intervention)) +
geom_point(size = 6, alpha = 0.30)+
geom_text(label = c("Standard", "E","D","C","B","A"), color = "black")+
labs(title = "Cost-Effectiveness Plane",
x = "Effectiveness (QALYs)",
y = "Cost ($)",
color = "Strategy")
library(tidyverse)
cea_plane <- data.frame(intervention = c("Standard", "E","D","C","B","A"), cost = c(5000, 12000, 10000, 25000, 35000, 55000), effectiveness = c(1, 1.5, 2, 3, 4, 5))
cea_plane
ggplot(cea_plane, aes(effectiveness, cost, color = intervention)) +
geom_point(size = 6, alpha = 0.30)+
geom_text(label = c("Standard", "E","D","C","B","A"), color = "black")+
labs(title = "Cost-Effectiveness of Strategies",
x = "Effectiveness (QALYs)",
y = "Cost ($)",
color = "Strategy")
R.version
R.version
setwd("~/OneDrive - McGill University/LTBI-Aust-CEA-master/Data")
tbi <- readRDS("2011estimates_v2.rds")
#View(tbi)
View(tbi%>%filter(is.na(LTBP)))
library(tidyverse)
# Read file in
tbi <- readRDS("2011estimates_v2.rds")
#View(tbi)
View(tbi%>%filter(is.na(LTBP)))
tbi <- readRDS("census_v9.rds")
#write.csv(tbi,"/Users/ajordan/OneDrive - McGill University/LTBI-Aust-CEA-master/Data/Outputs/tbi_est.csv", row.names = FALSE)
tbi <- tbi%>%select(-poptb, -year)
View(tbi%>%filter(is.na(LTBP)))
install.packages("GGally")
# Document used to add Age at Arrival (AARP) column, add WHO regions, eventually incidence bands will be added as well. Unnecessary columns also removed
rm(list = ls(all.names = TRUE))
gc()
library(tidyverse)
# Read file in
tbi <- readRDS("2011estimates_v2.rds")
#View(tbi)
View(tbi%>%filter(is.na(LTBP)))
#write.csv(tbi,"/Users/ajordan/OneDrive - McGill University/LTBI-Aust-CEA-master/Data/Outputs/tbi_est.csv", row.names = FALSE)
tbi <- tbi%>%select(-poptb, -year)
View(na.omit(tbi)%>%summarise(sum(LTBP)/sum(NUMP), TBI.prev.low = sum(LTBP.low)/sum(NUMP), TBI.prev.high = sum(LTBP.high)/sum(NUMP)))
# DATA CHECK=======================================================================================================
by_country <- na.omit(tbi)%>%
group_by(ISO3)%>%
summarise(TBI.prev = sum(LTBP)/sum(NUMP), TBI.prev.low = sum(LTBP.low)/sum(NUMP), TBI.prev.high = sum(LTBP.high)/sum(NUMP))
View(by_country)
View(na.omit(tbi)%>%
filter(ISO3%in%c("PHL", "USA", "CHN", "IND", "DEU", "AUS"))%>%
group_by(ISO3)%>%
summarise(sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP)))
View(na.omit(tbi)%>%
filter(ISO3%in%c("PHL", "USA", "CHN", "IND", "DEU", "AUS") & YARP%in%c(1890, 1931, 1950, 1980, 1990, 2000, 2014))%>%
group_by(ISO3,YARP)%>%
summarise(sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP)))
tbi_est <- tbi
# INCIDENCE BANDS====================================================================================================
# Merge incidence bands
tb_import <- read.csv("TB burden country copy.csv")
tb_inc  <- tb_import%>%filter(year == 2011)%>%select(iso3,  e_inc_100k)
colnames(tb_inc) <- c("ISO3", "e_inc_100k")
View(tb_inc)
tbi_data <- merge(tbi_est, tb_inc, by = "ISO3")
#View(tbi_data)
# Less bands
tbi_data_bands <- tbi_data%>%
mutate(inc_band_per100k = ifelse(
e_inc_100k < 50, "0-49", ifelse(
e_inc_100k >= 50 & e_inc_100k < 100, "50-99", ifelse(
e_inc_100k >= 100 & e_inc_100k < 200, "100-199",ifelse(
e_inc_100k >= 200 & e_inc_100k <= 10000, "200+", "No value")))))
View(na.omit(tbi_data_bands)%>%
group_by(inc_band_per100k)%>%
summarise(sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP)))
View(na.omit(tbi_data_bands)%>%
group_by(by_country, inc_band_per100k)%>%
summarise(sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP)))
View(na.omit(tbi_data_bands)%>%
group_by(ISO3, inc_band_per100k)%>%
summarise(sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP)))
inc_bands_narrow <- na.omit(tbi_data_bands)%>%
filter(inc_band_per100k == "50-99" & inc_band_per100k == "100-199")%>%
group_by(ISO3, inc_band_per100k)%>%
summarise(sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP))
max(inc_bands_narrow$`sum(LTBP)/sum(NUMP)`)
inc_bands_narrow <- na.omit(tbi_data_bands)%>%
filter(inc_band_per100k == "50-99" & inc_band_per100k == "100-199")%>%
group_by(ISO3, inc_band_per100k)%>%
summarise(tbi_prev = sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP))
max(inc_bands_narrow$tbi_prev)
View(inc_bands_narrow)
inc_bands_narrow <- na.omit(tbi_data_bands)%>%
filter(inc_band_per100k == "50-99" | inc_band_per100k == "100-199")%>%
group_by(ISO3, inc_band_per100k)%>%
summarise(tbi_prev = sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP))
View(inc_bands_narrow)
5,610,000/45270000
5610000/45270000
inc_bands_narrow <- na.omit(tbi_data_bands)%>%
filter(inc_band_per100k == "50-99" | inc_band_per100k == "100-199")%>%
group_by(ISO3, inc_band_per100k,YARP)%>%
summarise(tbi_prev = sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP))
View(inc_bands_narrow)
inc_bands_narrow <- na.omit(tbi_data_bands)%>%
filter(inc_band_per100k == "50-99" | inc_band_per100k == "100-199")%>%
summarise(tbi_prev = sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP))
View(inc_bands_narrow)
inc_bands_narrow <- na.omit(tbi_data_bands)%>%
filter(inc_band_per100k == "50-99" | inc_band_per100k == "100-199")%>%
group_by(ISO3, inc_band_per100k,YARP, AGEP)%>%
summarise(tbi_prev = sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP))
View(inc_bands_narrow)
inc_bands_narrow <- na.omit(tbi_data_bands)%>%
filter(inc_band_per100k == "50-99" | inc_band_per100k == "100-199")%>%
group_by(ISO3, inc_band_per100k,YARP, AGEP)%>%
summarise(tbi_prev = sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP))
View(inc_bands_narrow)
census_1970 <- readRDS("census2011_1970v3.rds")
# Fill in the NAs then delete duplicate values
census_1970 <- census_1970%>%arrange(ID)
View(census_1970)
census_1970v3 <- dplyr::distinct(na.locf(census_1970))
View(census_1970v3)
census_1970v3<-subset(census_1970v3,census_1970v3$YOBP<=census_1970v3$YARP)
nrow(census_1970v3)
# Remove anyone whose year of birth is less than or equal to YARP
#View(census_1970v4)
# Distribute population
census_1970v4<-census_1970v3%>%
group_by(YARP, AGEP)%>%
mutate(NUMPv2 = NUMP/max(row_number()))
View(census_1970v4%>%ungroup%>%
summarise(tot_pop = sum(as.numeric(NUMPv2))))
census_1970 <- readRDS("census2011_1970v3.rds")
# Fill in the NAs then delete duplicate values
census_1970 <- census_1970%>%arrange(ID)
View(census_1970)
census_1970v3 <- dplyr::distinct(na.locf(census_1970))
View(census_1970v3)
census_1970v3<-subset(census_1970v3,census_1970v3$YOBP<=census_1970v3$YARP)
nrow(census_1970v3)
# Remove anyone whose year of birth is less than or equal to YARP
#View(census_1970v4)
# Distribute population
census_1970v4<-census_1970v3%>%
group_by(YARP, AGEP)%>%
mutate(NUMPv2 = NUMP/max(row_number()))
View(census_1970v4%>%ungroup%>%
summarise(tot_pop = sum(as.numeric(NUMPv2))))
setwd("~/OneDrive - McGill University/LTBI-Aust-CEA-master/Census/Census 2011")
census_1970 <- readRDS("census2011_1970v3.rds")
# Fill in the NAs then delete duplicate values
census_1970 <- census_1970%>%arrange(ID)
View(census_1970)
census_1970v3 <- dplyr::distinct(na.locf(census_1970))
View(census_1970v3)
census_1970v3<-subset(census_1970v3,census_1970v3$YOBP<=census_1970v3$YARP)
nrow(census_1970v3)
# Remove anyone whose year of birth is less than or equal to YARP
#View(census_1970v4)
# Distribute population
census_1970v4<-census_1970v3%>%
group_by(YARP, AGEP)%>%
mutate(NUMPv2 = NUMP/max(row_number()))
View(census_1970v4%>%ungroup%>%
summarise(tot_pop = sum(as.numeric(NUMPv2))))
census_1970 <- readRDS("census2011_1970v3.rds")
# Fill in the NAs then delete duplicate values
census_1970 <- census_1970%>%arrange(ID)
View(census_1970)
census_1970v3 <- dplyr::distinct(na.locf(census_1970))
View(census_1970v3)
census_1970v3<-subset(census_1970v3,census_1970v3$YOBP<=census_1970v3$YARP)
nrow(census_1970v3)
# Remove anyone whose year of birth is less than or equal to YARP
#View(census_1970v4)
# Distribute population
census_1970v4<-census_1970v3%>%
group_by(YARP, AGEP)%>%
mutate(NUMPv2 = NUMP/max(row_number()))
View(census_1970v4%>%ungroup%>%
summarise(tot_pop = sum(as.numeric(NUMPv2))))
census_1970 <- readRDS("census2011_1970v3.rds")
census_1970 <- census_1970%>%arrange(ID)
census_1970v3 <- dplyr::distinct(na.locf(census_1970))
View(census_1970v3)
census_1970v3<-subset(census_1970v3,census_1970v3$YOBP<=census_1970v3$YARP)
library()
library(zoo)
census_1970v3 <- dplyr::distinct(na.locf(census_1970))
census_1970v3<-subset(census_1970v3,census_1970v3$YOBP<=census_1970v3$YARP)
nrow(census_1970v3)
# Distribute population
census_1970v4<-census_1970v3%>%
group_by(YARP, AGEP)%>%
mutate(NUMPv2 = NUMP/max(row_number()))
View(census_1970v4%>%ungroup%>%
summarise(tot_pop = sum(as.numeric(NUMPv2))))
# Distribute population
census_1970v4<-census_1970v3%>%
group_by(YARP)%>%
mutate(NUMPv2 = NUMP/max(row_number()))
View(census_1970v4%>%ungroup%>%
summarise(tot_pop = sum(as.numeric(NUMPv2))))
# Distribute population
census_1970v4<-census_1970v3%>%
group_by(AGEP)%>%
mutate(NUMPv2 = NUMP/max(row_number()))
View(census_1970v4%>%ungroup%>%
summarise(tot_pop = sum(as.numeric(NUMPv2))))
census_1970 <- readRDS("census2011_1970v3.rds")
# Fill in the NAs then delete duplicate values
census_1970 <- census_1970%>%arrange(ID)
View(census_1970)
census_1970v3 <- dplyr::distinct(na.locf(census_1970))
View(census_1970v3)
census_1970v3<-subset(census_1970v3,census_1970v3$YOBP<=census_1970v3$YARP)
nrow(census_1970v3)
# Remove anyone whose year of birth is less than or equal to YARP
#View(census_1970v4)
# Distribute population
census_1970v4<-census_1970v3%>%
group_by(AGEP)%>%
mutate(NUMPv2 = NUMP/max(row_number()))
View(census_1970v4%>%ungroup%>%
summarise(tot_pop = sum(as.numeric(NUMPv2))))
census_1970 <- readRDS("census2011_1970v3.rds")
# Fill in the NAs then delete duplicate values
census_1970 <- census_1970%>%arrange(ID)
View(census_1970)
census_1970v3 <- dplyr::distinct(na.locf(census_1970))
View(census_1970v3)
census_1970v3<-subset(census_1970v3,census_1970v3$YOBP<=census_1970v3$YARP)
nrow(census_1970v3)
# Remove anyone whose year of birth is less than or equal to YARP
#View(census_1970v4)
# Distribute population
census_1970v4<-census_1970v3%>%
group_by(AGEP)%>%
mutate(NUMPv2 = NUMP/max(row_number()))
View(census_1970v4%>%ungroup%>%
summarise(tot_pop = sum(as.numeric(NUMPv2))))
# Distribute population
census_1970v4<-census_1970v3%>%
group_by(YARP_group)%>%
mutate(NUMPv2 = NUMP/max(row_number()))
View(census_1970v4%>%ungroup%>%
summarise(tot_pop = sum(as.numeric(NUMPv2))))
# Distribute population
census_1970v4<-census_1970v3%>%
group_by(YARP_group, AGEP)%>%
mutate(NUMPv2 = NUMP/max(row_number()))
View(census_1970v4%>%ungroup%>%
summarise(tot_pop = sum(as.numeric(NUMPv2))))
View(census_1970v3)
# Distribute population
census_1970v4<-census_1970v3%>%
group_by(YARP_group, AGE_GROUP)%>%
mutate(NUMPv2 = NUMP/max(row_number()))
View(census_1970v4%>%ungroup%>%
summarise(tot_pop = sum(as.numeric(NUMPv2))))
inc_bands_narrow <- na.omit(tbi_data_bands)%>%
filter(inc_band_per100k == "50-99" | inc_band_per100k == "100-199")%>%
group_by(ISO3, inc_band_per100k,YARP)%>%
summarise(tbi_prev = sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP))
View(inc_bands_narrow)
aa<- na.omit(tbi_data_bands)%>%
filter(ISO3 != "ROU")%>%
group_by(inc_band_per100k)%>%
summarise(tbi_prev = sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP))
View(aa)
aa<- na.omit(tbi_data_bands)%>%
filter(!ISO3%in%c("ROU", "KOR"))%>%
group_by(inc_band_per100k)%>%
summarise(tbi_prev = sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP))
View(aa)
aa<- na.omit(tbi_data_bands)%>%
filter(!ISO3%in%c("CHN"))%>%
group_by(inc_band_per100k)%>%
summarise(tbi_prev = sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP))
View(aa)
aa<- na.omit(tbi_data_bands)%>%
filter(!ISO3%in%c("CHN", "ROU"))%>%
group_by(inc_band_per100k)%>%
summarise(tbi_prev = sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP))
View(aa)
tb_import <- read.csv("TB burden country copy.csv")
tb_inc  <- tb_import%>%filter(year == 2016)%>%select(iso3,  e_inc_100k)
colnames(tb_inc) <- c("ISO3", "e_inc_100k")
View(tb_inc)
tbi_data <- merge(tbi_est, tb_inc, by = "ISO3")
#View(tbi_data)
# Less bands
tbi_data_bands <- tbi_data%>%
mutate(inc_band_per100k = ifelse(
e_inc_100k < 50, "0-49", ifelse(
e_inc_100k >= 50 & e_inc_100k < 100, "50-99", ifelse(
e_inc_100k >= 100 & e_inc_100k < 200, "100-199",ifelse(
e_inc_100k >= 200 & e_inc_100k <= 10000, "200+", "No value")))))
View(na.omit(tbi_data_bands)%>%
group_by(inc_band_per100k)%>%
summarise(sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP)))
inc_bands_narrow <- na.omit(tbi_data_bands)%>%
filter(inc_band_per100k == "50-99" | inc_band_per100k == "100-199")%>%
group_by(ISO3, inc_band_per100k,YARP)%>%
summarise(tbi_prev = sum(LTBP)/sum(NUMP), sum(LTBP.low)/sum(NUMP), sum(LTBP.high)/sum(NUMP))
View(inc_bands_narrow)
