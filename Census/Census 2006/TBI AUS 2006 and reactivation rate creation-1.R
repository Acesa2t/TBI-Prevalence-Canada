#'===================================================================================================================#
#'
#' This script takes annual risk of infection (ARI) values developed by Pete Dodd and Rein Houben and 
#' generates force of infection (FOI) estimates for differing population groups (by age, year of arrival 
#' and country of birth), which can then be converted to probabilities/risk of infection and combined 
#' with census datasets to arrive at prevalence of TB infection estimates for a particular setting.
#' The script will  calculate the median hazard for each population group in the census and, additionally, will provide lower and 
#' upper percentile estimates, as defined by the following
#' objects.
#' These are also combined with TB data to provide estimates of reactivation rates/risks.
#'
#' INPUTS:
#'  - ARTI estimates generated by Pete Dodd and Rein Houben ("5000repLARI.Rdata" and "200repLARI.Rdata")
#'  - Census data by age, year of arrival, and country of birth. This file needs to be cleaned
#'  and reshaped, if necessary, with the "CleanseCensus" function to create a dataset with the
#'  following columns:
#'      -  NUMP - Number of persons in the population group
#'      -  AGEP - Age of population group
#'      -  YARP - Year of arrival of population group
#'      -  YOBP - Year of birth of population group
#'      -  BPLP - Birth country of population group
#'      -  ISO3 - 3 letter country code corresponding to birth country 
#'      -  CNSY - Census year
#'  - TB data by year of notification, age, year of arrival, and country of birth. This file needs to be cleaned
#'  and reshaped, if necessary, with the "CleanseTBdata" function to create a dataset with the
#'  following columns:
#'      -  year - Year of notification
#'      -  poptb - Number of TB cases in the population group
#'      -  AGEP - Age of population group
#'      -  YARP - Year of arrival of population group
#'      -  ISO3 - 3 letter country code corresponding to birth country 
#' 
#' OUTPUTS:
#' - A master table of all TB infection probabilities and outcomes, 
#' stored in the outputs path specified below (path.out).
#'      -  NUMP - Number of persons in the population group
#'      -  AGEP - Age of population group
#'      -  YARP - Year of arrival of population group
#'      -  YOBP - Year of birth of population group
#'      -  BPLP - Birth country of population group
#'      -  ISO3 - 3 letter country code corresponding to birth country 
#'      -  CNSY - Census year
#'      -  LTBP - Number of in the population estimated to have been infected
#'      -  PROB - Probability/risk of infection in the population group
#' 
#' Author: Katie Dale and Milinda Abayawardana
#' Date created: 2016-2021
#'===================================================================================================================#

rm(list = ls(all.names = TRUE)) # Clears all objects includes hidden objects.
gc() # Frees up memory and report the memory usage.

#' LOAD REQUIRED LIBRARIES ==========================================================================================#

library(data.table)
library(tidyverse)
library(reshape2)
library(countrycode)

#' DEFINE USEFUL OBJECTS (INPUT & OUTPUT PATHS, FUNCTIONS, STUDY PERIOD ETC) ========================================#

#' The iso3 value for the country from which the census data is from

census.iso3 <- "AUS"

census.year <- 2006

#' This script will calculate the median hazard for each population
#' group in the census and, additionally, will provide lower and 
#' upper percentile estimates, as defined by the following
#' objects.
low.percentile <- 0.25
high.percentile <- 0.75

#' Data inputs file path
path.in <- "/Users/ajordan/OneDrive - McGill University/LTBI-Aust-CEA-master/Data/"

#' Output file path
path.out <- "/Users/ajordan/OneDrive - McGill University/LTBI-Aust-CEA-master/Data/"

#' Source all functions, which are located within the "Functions" file.
source(paste0(path.in, "Functions original.R"))

#' INPUTS ===========================================================================================================#

#' Load the hazard data from Houben & Dodd
# filename <- paste0(path.in, "5000repLARI.Rdata")
# 
# tbhaz.5000rep <- load(filename)
# tbhaz.5000rep <- LARI
# rm(LARI)

filename <- paste0(path.in, "200repLARI.Rdata")
load(filename)
tbhaz.200repAUS <- as.data.table(rundata)
rm(rundata)

#' Load the census data 
census <- read.csv(paste0(path.in, "Australia 2006.csv"), skip = 9, header = T)
View(census)

#colnames(census) <- c("ISO3", "WHO_R","AGEP","AGE_GROUP","YARP","BPLP","CNSY","YOBP", "YARP_GROUP", "NUMP")
#View(census)


# census <- read.csv(paste0(path.in, "Australia 2006.csv"), skip = 9, header = T)
# census <- read.csv(paste0(path.in, "Australia 2011.csv"), skip = 9, header = T)
#View(census)
#' Load TB data 
tb <- read.csv(paste0(path.in, "NNDSS skeleton.csv"), header = T)

#' DATA PREP ========================================================================================================#

#' Creating cumulative FOIs and adjusting for census year.
#' Also expanding the table's year range ( 1889 to 2016).
tbhaz.200repAUS <- tbhazprep.function(tbhaz.200repAUS)
View(tbhaz.200repAUS)
View(tbhaz.200repAUS%>%filter(iso3%in%c("PRT","RUS","RWA") & year > 1920)%>%group_by(iso3, year)%>%summarise(mean(FOI)))
write_csv(tbhaz.200repAUS%>%filter(iso3%in%c("PRT","RUS","RWA")), file = "/Users/ajordan/OneDrive - McGill University/LTBI-Aust-CEA-master/Census/Census 2006/tb_hazards_AUS_2006.csv")
# tbhaz.5000rep <- tbhazprep.function(tbhaz.5000rep)

#' Clean the census data so that it has the following columns
#' AGEP, YARP, cob, NUMP, CNSY, YOBP and ISO3
census <- CleanseCensus(census)
View(census)
#' Clean the TB data so that it has the following columns
#' AGEP, YARP, cob, NUMP, year, YOBP and ISO3
tb <- CleanseTBdata(tb)


tb <- subset(tb, year == census.year)
tb <- as.data.table(tb)
tb[, CNSY := as.numeric(year)]

#' Checking if there are any countries that don't have an 
#' ISO3 match from Houben and Dodd.
setdiff(census$ISO3, tbhaz.200repAUS$iso3) 

setdiff(tb$ISO3, census$ISO3) 

setdiff(tb$ISO3, tbhaz.200repAUS$iso3) 

setdiff(tbhaz.200repAUS$iso3, census$ISO3) #' All countries in the census data are captured in Houben & Dodd data.

#' Create a master look-up table of all probabilities of infection 
#' for each population group, by using the census and tb tables 
#' to get a list of unique ISO codes.
master.Prob <- CreateProbTables()

#' ==================edited out the ISO3 look-up for 5000 vs 200 rep
#' Subset the look-up table by ISO3 depending on whether the relevant tbhaz values 
#' are in the tbhaz.200 or tbhaz.5000 data set.
# prob.Inf5000 <- master.Prob[ISO3 == "CHN" | ISO3 == "GBR" | ISO3 == "IND" |
#                               ISO3 == "MYS" | ISO3 == "PHL" | ISO3 == "VNM"]
# 
# prob.Inf200AUS <- master.Prob[ ISO3 != census.iso3 & ISO3 != "CHN" & ISO3 != "GBR" 
#                             & ISO3 != "IND" & ISO3 != "MYS" & ISO3 != "PHL" 
#                             & ISO3 != "VNM"]

prob.Inf200AUS <- master.Prob[ !(ISO3 %in% c(census.iso3))] 

#' Also create a separate look-up table for the locally born.
prob.Inf.local <- master.Prob[ISO3 == census.iso3]

#' Tidy
rm(master.Prob)

#' The following function calculates hazards for the locally
#' born population (prob.Inf.local). The percentiles
#' that are required can be defined earlier in the script.

prob.Inf.local <- TBhazard.calc.function.local.born(prob.Inf.local, tbhaz.200repAUS)
View(prob.Inf.local)
#' Saving and removing file (memory management)
saveRDS(prob.Inf.local, file = paste0(path.out, "prob.Inf.local.rds"))
rm(prob.Inf.local)

#' The following function calculates hazards for the population
#' groups in the prob.Inf200AUS look-up table. The percentiles
#' that are required can be defined earlier in the script.
#' Because the hazard calculations are quite memory intensive, 
#' I've split the data into groups by year of birth, before 
#' running the function on it, so the chunks are more manageable.
#' Then the separate chunks are subsequently bound together again.

prob.Inf200AUS[YOBP < 1930 , YOBPgroup := 1]
prob.Inf200AUS[YOBP > 1929 & YOBP < 1960 , YOBPgroup := 2]
prob.Inf200AUS[YOBP > 1959 & YOBP < 1980 , YOBPgroup := 3]
prob.Inf200AUS[YOBP > 1979 & YOBP < 2000 , YOBPgroup := 4]
prob.Inf200AUS[YOBP > 1999 & YOBP < 2010 , YOBPgroup := 5]
prob.Inf200AUS[YOBP > 2009 , YOBPgroup := 6]

yob.split <- split(prob.Inf200AUS, prob.Inf200AUS$YOBPgroup)

yob.split <- lapply(yob.split, TBhazard.calc.function.overseas.born, tbhaz.200repAUS)
#View(tbhaz.200repAUS)

prob.Inf200AUS <- do.call("rbind", yob.split)
#yob.split[[4]]
#' Tidy
#'
rm(yob.split)

#' Saving and removing file (memory management)
saveRDS(prob.Inf200AUS, file = paste0(path.out, "prob.Inf200AUS.rds"))
View(prob.Inf200AUS)
#' Tidy
rm(prob.Inf200AUS)

#' Repeat the same as above for the 5000rep look-up table.
#' However, with this table it is simplest to split it by ISO3, 
#' rather than year of birth (because there are only six ISO3).

#=================Removing iso3.split=============================
#iso3.split <- split(prob.Inf5000, prob.Inf5000$ISO3)
#' 
#iso3.split <- lapply(iso3.split, TBhazard.calc.function.overseas.born, tbhaz.5000rep)
#' 
#prob.Inf5000 <- do.call("rbind", iso3.split)
#' 
#' #' Saving and removing file (memory management)
#saveRDS(prob.Inf5000, file = paste0(path.out, "prob.Inf5000.rds"))
#rm(prob.Inf5000, iso3.split)

#' Order the census data.table.
census <- setorder(census, ISO3, YOBP, YARP)

#' Load the look-up tables back in.
prob.Inf200AUS <- readRDS(paste0(path.out, "prob.Inf200AUS.rds"))
#prob.Inf5000 <- readRDS(paste0(path.out, "prob.Inf5000.rds"))
prob.Inf.local <- readRDS(paste0(path.out, "prob.Inf.local.rds"))

#' Bind the look-up tables altogether to make the master look-up.
prob.InfAUS <- rbind(prob.Inf.local, prob.Inf200AUS, fill = T)

#' Tidy ==========EDITED OUT prob.Inf5000
rm(prob.Inf.local, prob.Inf200AUS)

#' Calculating the probability of infection (PROB)
#' from the hazards.
prob.InfAUS[, PROB.med := 1 - exp(-(H.med))]
prob.InfAUS[, PROB.low := 1 - exp(-(H.low))]
prob.InfAUS[, PROB.high := 1 - exp(-(H.high))]

#' Calculating the number of individuals in the population estimated 
#' to have been infected (LTBP).

census <- as.data.table(census)
census[prob.InfAUS, LTBP := NUMP * PROB.med, on = .(ISO3, YOBP, YARP)]
census[prob.InfAUS, LTBP.low := NUMP * PROB.low, on = .(ISO3, YOBP, YARP)]
census[prob.InfAUS, LTBP.high := NUMP * PROB.high, on = .(ISO3, YOBP, YARP)]

census2 <- na.omit(census)%>%mutate(AARP = YARP-YOBP)%>%group_by(NUMP)
#saveRDS(census2, file = paste0(path.out, "AUScensus_2006_v4.rds"))
saveRDS(prob.InfAUS, file = paste0(path.out, "AUSprob.Inf_v10.rds"))

vector_test <- c("PHL", "IND","CHN","USA","DEU","GBR", "VNM", "HKG","MAC")
View(census)

tbi.func.test <- function(df, vec){
  df3 <- data.frame(ISO3 = character(), med = numeric())
  
  for(i in 1:length(vec)){
    df3[i,1] <- vec[i]
    df2 <- subset(df,df$ISO3==vec[i])
    df3[i,2]<-weighted.median(df2$AARP, df2$NUMP)
  }    
  print(df3)
}


View(tbi.func.test(df=census2, vec=vector_test))


View(na.omit(census)%>%group_by(ISO3)%>%filter(ISO3%in%c("PHL", "IND","CHN","USA","DEU","GBR", "VNM", "HKG","MAC"))%>%mutate(AARP = YARP - YOBP)%>%summarize(tbi_prev_AUS = sum(LTBP)/sum(NUMP), med_yarp = median(YARP), med_aarp = median(AARP), med_age = median(AGEP)))

census_na <- na.omit(census)
View(prob.InfAUS)
length(unique(census_na$ISO3))

#' Check the number missing LTBP information
census[is.na(LTBP), sum(NUMP)]

#' Check the percentage missing LTBP information
#' (some investigation may need to be done to work out
#' why these population groups have missing data. It
#' could be because some countries of birth were not
#' mapped to an ISO3 value).
census[is.na(LTBP), sum(NUMP)]/census[, sum(NUMP)] * 100

#' Merge in the TB data
census <- merge(census, tb, by = c("AGEP", "ISO3", "CNSY", "YARP"), all.x = T)
View(census)

write.csv(census,"/Users/ajordan/OneDrive - McGill University/LTBI-Aust-CEA-master/Data/Outputs/AUSestimates_10.csv", row.names = FALSE)



#' DATA OUTPUTS =======================================================================================================#

#' Save all the objects that haven't yet been saved.
saveRDS(prob.Inf, file = paste0(path.out, "AUSprob.Inf_v10.rds"))

saveRDS(census, file = paste0(path.out, "AUScensus_v10.rds"))


